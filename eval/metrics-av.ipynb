{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a95e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/test/PycharmProjects\")\n",
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "292a1866",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = './example/captions_val2014.json'\n",
    "results_file = './example/captions_val2014_fakecap_results.json'\n",
    "\n",
    "# create coco object and coco_result object\n",
    "# coco = COCO(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199449dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create coco_eval object by taking coco and coco_result\n",
    "# coco_result = coco.loadRes(results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd7f9eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bleu\t\t\t\t\t pycocoevalcap.egg-info\r\n",
      "cider\t\t\t\t\t README.md\r\n",
      "df_av_test_after_fat.pk\t\t\t rouge\r\n",
      "df_av_test_before_fat.pk\t\t setup.py\r\n",
      "drive-download-20220901T162327Z-001.zip  spice\r\n",
      "eval.py\t\t\t\t\t test_after_trained_on_all_ped.pk\r\n",
      "example\t\t\t\t\t test_before_trained_on_all_ped.pk\r\n",
      "license.txt\t\t\t\t tokenizer\r\n",
      "meteor\t\t\t\t\t venv\r\n",
      "metrics.ipynb\t\t\t\t wit_av_test_after.pk\r\n",
      "metrics-ped.ipynb\t\t\t wit_ped_test_after.pk\r\n",
      "__pycache__\r\n"
     ]
    }
   ],
   "source": [
    "! ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac90f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(annotation_file, 'r') as f:\n",
    "    jdata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbd13c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info\n",
      "images\n",
      "licenses\n",
      "type\n",
      "annotations\n"
     ]
    }
   ],
   "source": [
    "for el in jdata:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7721a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = '.'\n",
    "bf = f'{d_path}/df_av_test_before_fat.pk'\n",
    "af_wit = f'{d_path}/wit_av_test_after.pk'\n",
    "af_fat = f'{d_path}/df_av_test_after_fat.pk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "610c87d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>image</th>\n",
       "      <th>topic2caption_sim</th>\n",
       "      <th>concept2caption_sim</th>\n",
       "      <th>topics</th>\n",
       "      <th>tag</th>\n",
       "      <th>ofa_caption</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Firefighting Drones</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.512088</td>\n",
       "      <td>0.489315</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 0, 'sensor': 0, 'uav'...</td>\n",
       "      <td>Airmen with a drone in front of a gas pipeline</td>\n",
       "      <td>uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>DJI mavic 2 pro in flight</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.506123</td>\n",
       "      <td>0.303162</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...</td>\n",
       "      <td>Cessna A drone flying in the air</td>\n",
       "      <td>drone uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>A small UAS is seen flying during at the US Ar...</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.456664</td>\n",
       "      <td>0.440849</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...</td>\n",
       "      <td>A drone flies through the air with arrows in t...</td>\n",
       "      <td>drone uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>Ruko F11 GIM2 Drone with Camera for Adults 4K ...</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.425304</td>\n",
       "      <td>0.273581</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...</td>\n",
       "      <td>Cessna B17 with 4 Drones and 4 Brones with 4 d</td>\n",
       "      <td>drone uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>The MQ9 Reaper</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>0.226430</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...</td>\n",
       "      <td>Cessna B17 B17 in flight</td>\n",
       "      <td>drone uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>1931</td>\n",
       "      <td>1931</td>\n",
       "      <td>In our globalized world aviation increasingly ...</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>0.481348</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 1, 'airline': 1, 'tower': 0, '911...</td>\n",
       "      <td>Airports logo on the door of an airplane</td>\n",
       "      <td>aircraft airline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>1947</td>\n",
       "      <td>1947</td>\n",
       "      <td>Lufthansa Business Class on longhaul aircraft</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.333263</td>\n",
       "      <td>0.526307</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 1, 'airline': 1, 'tower': 0, '911...</td>\n",
       "      <td>A passenger sleeps in the aisle of an airplane</td>\n",
       "      <td>aircraft airline flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1969</td>\n",
       "      <td>1969</td>\n",
       "      <td>The Boeing 7478 has inherited the good looks o...</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.309636</td>\n",
       "      <td>0.431361</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 1, 'airline': 1, 'tower': 0, '911...</td>\n",
       "      <td>Lufthansa is the worlds largest airline</td>\n",
       "      <td>aircraft airline plane flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>911 Attacks Pentagon</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.655778</td>\n",
       "      <td>0.354867</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 1, 'airline': 0, 'tower': 0, '911...</td>\n",
       "      <td>A painting of two pilots in a cockpit with a f...</td>\n",
       "      <td>aircraft pentagon plane flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>911 flight 93 memorial</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.528041</td>\n",
       "      <td>0.310519</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 0, 'airline': 0, 'tower': 0, '911...</td>\n",
       "      <td>A repatriation plaque at the British museum in...</td>\n",
       "      <td>911 hijacker hijack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uniq_id  image_id                                            caption  \\\n",
       "0          4         4                                Firefighting Drones   \n",
       "1         27        27                          DJI mavic 2 pro in flight   \n",
       "2         51        51  A small UAS is seen flying during at the US Ar...   \n",
       "3        102       102  Ruko F11 GIM2 Drone with Camera for Adults 4K ...   \n",
       "4        130       130                                     The MQ9 Reaper   \n",
       "..       ...       ...                                                ...   \n",
       "677     1931      1931  In our globalized world aviation increasingly ...   \n",
       "678     1947      1947      Lufthansa Business Class on longhaul aircraft   \n",
       "679     1969      1969  The Boeing 7478 has inherited the good looks o...   \n",
       "680     1979      1979                               911 Attacks Pentagon   \n",
       "681     1992      1992                             911 flight 93 memorial   \n",
       "\n",
       "     topic_id labels                                              image  \\\n",
       "0          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "1          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "2          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "3          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "4          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "..        ...    ...                                                ...   \n",
       "677       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "678       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "679       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "680       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "681       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "\n",
       "     topic2caption_sim  concept2caption_sim topics  \\\n",
       "0             0.512088             0.489315      a   \n",
       "1             0.506123             0.303162      a   \n",
       "2             0.456664             0.440849      a   \n",
       "3             0.425304             0.273581      a   \n",
       "4             0.246585             0.226430      a   \n",
       "..                 ...                  ...    ...   \n",
       "677           0.265668             0.481348      j   \n",
       "678           0.333263             0.526307      j   \n",
       "679           0.309636             0.431361      j   \n",
       "680           0.655778             0.354867      j   \n",
       "681           0.528041             0.310519      j   \n",
       "\n",
       "                                                   tag  \\\n",
       "0    {'aircraft': 0, 'drone': 0, 'sensor': 0, 'uav'...   \n",
       "1    {'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...   \n",
       "2    {'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...   \n",
       "3    {'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...   \n",
       "4    {'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...   \n",
       "..                                                 ...   \n",
       "677  {'aircraft': 1, 'airline': 1, 'tower': 0, '911...   \n",
       "678  {'aircraft': 1, 'airline': 1, 'tower': 0, '911...   \n",
       "679  {'aircraft': 1, 'airline': 1, 'tower': 0, '911...   \n",
       "680  {'aircraft': 1, 'airline': 0, 'tower': 0, '911...   \n",
       "681  {'aircraft': 0, 'airline': 0, 'tower': 0, '911...   \n",
       "\n",
       "                                           ofa_caption  \\\n",
       "0       Airmen with a drone in front of a gas pipeline   \n",
       "1                     Cessna A drone flying in the air   \n",
       "2    A drone flies through the air with arrows in t...   \n",
       "3       Cessna B17 with 4 Drones and 4 Brones with 4 d   \n",
       "4                             Cessna B17 B17 in flight   \n",
       "..                                                 ...   \n",
       "677           Airports logo on the door of an airplane   \n",
       "678     A passenger sleeps in the aisle of an airplane   \n",
       "679            Lufthansa is the worlds largest airline   \n",
       "680  A painting of two pilots in a cockpit with a f...   \n",
       "681  A repatriation plaque at the British museum in...   \n",
       "\n",
       "                                  gt  \n",
       "0              uav uavs unmanned uas  \n",
       "1        drone uav uavs unmanned uas  \n",
       "2        drone uav uavs unmanned uas  \n",
       "3        drone uav uavs unmanned uas  \n",
       "4        drone uav uavs unmanned uas  \n",
       "..                               ...  \n",
       "677                 aircraft airline  \n",
       "678          aircraft airline flight  \n",
       "679    aircraft airline plane flight  \n",
       "680   aircraft pentagon plane flight  \n",
       "681              911 hijacker hijack  \n",
       "\n",
       "[682 rows x 12 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_wp = pd.read_pickle(bf)\n",
    "# df_wp = pd.read_pickle(af_wit)\n",
    "df_wp = pd.read_pickle(af_fat)\n",
    "df_wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af1a3d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gt(tag):\n",
    "    context = []\n",
    "    for el in tag:\n",
    "        if tag[el]:\n",
    "            context.append(el)\n",
    "    if not context:\n",
    "        context = None\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f63266d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_con_gt(tag):\n",
    "    context = \"\"\n",
    "    for el in tag:\n",
    "        if tag[el]:\n",
    "            context = context + \" \" + el\n",
    "    if not context:\n",
    "        context = None\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa95248b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>image</th>\n",
       "      <th>topic2caption_sim</th>\n",
       "      <th>concept2caption_sim</th>\n",
       "      <th>topics</th>\n",
       "      <th>tag</th>\n",
       "      <th>ofa_caption</th>\n",
       "      <th>gt</th>\n",
       "      <th>con_gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Firefighting Drones</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.512088</td>\n",
       "      <td>0.489315</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 0, 'sensor': 0, 'uav'...</td>\n",
       "      <td>Airmen with a drone in front of a gas pipeline</td>\n",
       "      <td>[uav, uavs, unmanned, uas]</td>\n",
       "      <td>uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>DJI mavic 2 pro in flight</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.506123</td>\n",
       "      <td>0.303162</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...</td>\n",
       "      <td>Cessna A drone flying in the air</td>\n",
       "      <td>[drone, uav, uavs, unmanned, uas]</td>\n",
       "      <td>drone uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>A small UAS is seen flying during at the US Ar...</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.456664</td>\n",
       "      <td>0.440849</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...</td>\n",
       "      <td>A drone flies through the air with arrows in t...</td>\n",
       "      <td>[drone, uav, uavs, unmanned, uas]</td>\n",
       "      <td>drone uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>102</td>\n",
       "      <td>Ruko F11 GIM2 Drone with Camera for Adults 4K ...</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.425304</td>\n",
       "      <td>0.273581</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...</td>\n",
       "      <td>Cessna B17 with 4 Drones and 4 Brones with 4 d</td>\n",
       "      <td>[drone, uav, uavs, unmanned, uas]</td>\n",
       "      <td>drone uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>The MQ9 Reaper</td>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.246585</td>\n",
       "      <td>0.226430</td>\n",
       "      <td>a</td>\n",
       "      <td>{'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...</td>\n",
       "      <td>Cessna B17 B17 in flight</td>\n",
       "      <td>[drone, uav, uavs, unmanned, uas]</td>\n",
       "      <td>drone uav uavs unmanned uas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>1931</td>\n",
       "      <td>1931</td>\n",
       "      <td>In our globalized world aviation increasingly ...</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.265668</td>\n",
       "      <td>0.481348</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 1, 'airline': 1, 'tower': 0, '911...</td>\n",
       "      <td>Airports logo on the door of an airplane</td>\n",
       "      <td>[aircraft, airline]</td>\n",
       "      <td>aircraft airline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>1947</td>\n",
       "      <td>1947</td>\n",
       "      <td>Lufthansa Business Class on longhaul aircraft</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.333263</td>\n",
       "      <td>0.526307</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 1, 'airline': 1, 'tower': 0, '911...</td>\n",
       "      <td>A passenger sleeps in the aisle of an airplane</td>\n",
       "      <td>[aircraft, airline, flight]</td>\n",
       "      <td>aircraft airline flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>1969</td>\n",
       "      <td>1969</td>\n",
       "      <td>The Boeing 7478 has inherited the good looks o...</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.309636</td>\n",
       "      <td>0.431361</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 1, 'airline': 1, 'tower': 0, '911...</td>\n",
       "      <td>Lufthansa is the worlds largest airline</td>\n",
       "      <td>[aircraft, airline, plane, flight]</td>\n",
       "      <td>aircraft airline plane flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>1979</td>\n",
       "      <td>1979</td>\n",
       "      <td>911 Attacks Pentagon</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.655778</td>\n",
       "      <td>0.354867</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 1, 'airline': 0, 'tower': 0, '911...</td>\n",
       "      <td>A painting of two pilots in a cockpit with a f...</td>\n",
       "      <td>[aircraft, pentagon, plane, flight]</td>\n",
       "      <td>aircraft pentagon plane flight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1992</td>\n",
       "      <td>1992</td>\n",
       "      <td>911 flight 93 memorial</td>\n",
       "      <td>220</td>\n",
       "      <td></td>\n",
       "      <td>/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...</td>\n",
       "      <td>0.528041</td>\n",
       "      <td>0.310519</td>\n",
       "      <td>j</td>\n",
       "      <td>{'aircraft': 0, 'airline': 0, 'tower': 0, '911...</td>\n",
       "      <td>A repatriation plaque at the British museum in...</td>\n",
       "      <td>[911, hijacker, hijack]</td>\n",
       "      <td>911 hijacker hijack</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>682 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     uniq_id  image_id                                            caption  \\\n",
       "0          4         4                                Firefighting Drones   \n",
       "1         27        27                          DJI mavic 2 pro in flight   \n",
       "2         51        51  A small UAS is seen flying during at the US Ar...   \n",
       "3        102       102  Ruko F11 GIM2 Drone with Camera for Adults 4K ...   \n",
       "4        130       130                                     The MQ9 Reaper   \n",
       "..       ...       ...                                                ...   \n",
       "677     1931      1931  In our globalized world aviation increasingly ...   \n",
       "678     1947      1947      Lufthansa Business Class on longhaul aircraft   \n",
       "679     1969      1969  The Boeing 7478 has inherited the good looks o...   \n",
       "680     1979      1979                               911 Attacks Pentagon   \n",
       "681     1992      1992                             911 flight 93 memorial   \n",
       "\n",
       "     topic_id labels                                              image  \\\n",
       "0          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "1          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "2          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "3          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "4          31         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "..        ...    ...                                                ...   \n",
       "677       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "678       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "679       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "680       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "681       220         /9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBw...   \n",
       "\n",
       "     topic2caption_sim  concept2caption_sim topics  \\\n",
       "0             0.512088             0.489315      a   \n",
       "1             0.506123             0.303162      a   \n",
       "2             0.456664             0.440849      a   \n",
       "3             0.425304             0.273581      a   \n",
       "4             0.246585             0.226430      a   \n",
       "..                 ...                  ...    ...   \n",
       "677           0.265668             0.481348      j   \n",
       "678           0.333263             0.526307      j   \n",
       "679           0.309636             0.431361      j   \n",
       "680           0.655778             0.354867      j   \n",
       "681           0.528041             0.310519      j   \n",
       "\n",
       "                                                   tag  \\\n",
       "0    {'aircraft': 0, 'drone': 0, 'sensor': 0, 'uav'...   \n",
       "1    {'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...   \n",
       "2    {'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...   \n",
       "3    {'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...   \n",
       "4    {'aircraft': 0, 'drone': 1, 'sensor': 0, 'uav'...   \n",
       "..                                                 ...   \n",
       "677  {'aircraft': 1, 'airline': 1, 'tower': 0, '911...   \n",
       "678  {'aircraft': 1, 'airline': 1, 'tower': 0, '911...   \n",
       "679  {'aircraft': 1, 'airline': 1, 'tower': 0, '911...   \n",
       "680  {'aircraft': 1, 'airline': 0, 'tower': 0, '911...   \n",
       "681  {'aircraft': 0, 'airline': 0, 'tower': 0, '911...   \n",
       "\n",
       "                                           ofa_caption  \\\n",
       "0       Airmen with a drone in front of a gas pipeline   \n",
       "1                     Cessna A drone flying in the air   \n",
       "2    A drone flies through the air with arrows in t...   \n",
       "3       Cessna B17 with 4 Drones and 4 Brones with 4 d   \n",
       "4                             Cessna B17 B17 in flight   \n",
       "..                                                 ...   \n",
       "677           Airports logo on the door of an airplane   \n",
       "678     A passenger sleeps in the aisle of an airplane   \n",
       "679            Lufthansa is the worlds largest airline   \n",
       "680  A painting of two pilots in a cockpit with a f...   \n",
       "681  A repatriation plaque at the British museum in...   \n",
       "\n",
       "                                      gt                           con_gt  \n",
       "0             [uav, uavs, unmanned, uas]            uav uavs unmanned uas  \n",
       "1      [drone, uav, uavs, unmanned, uas]      drone uav uavs unmanned uas  \n",
       "2      [drone, uav, uavs, unmanned, uas]      drone uav uavs unmanned uas  \n",
       "3      [drone, uav, uavs, unmanned, uas]      drone uav uavs unmanned uas  \n",
       "4      [drone, uav, uavs, unmanned, uas]      drone uav uavs unmanned uas  \n",
       "..                                   ...                              ...  \n",
       "677                  [aircraft, airline]                 aircraft airline  \n",
       "678          [aircraft, airline, flight]          aircraft airline flight  \n",
       "679   [aircraft, airline, plane, flight]    aircraft airline plane flight  \n",
       "680  [aircraft, pentagon, plane, flight]   aircraft pentagon plane flight  \n",
       "681              [911, hijacker, hijack]              911 hijacker hijack  \n",
       "\n",
       "[682 rows x 13 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wp['gt'] = df_wp.apply(lambda x: create_gt(x.tag), axis=1)\n",
    "df_wp['con_gt'] = df_wp.apply(lambda x: create_con_gt(x.tag), axis=1)\n",
    "df_wp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc5f1deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "682"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_wp['gt'].isna().sum())\n",
    "df_wp = df_wp[df_wp['gt'].notna()]\n",
    "df_wp = df_wp.reset_index(drop=True)\n",
    "len(df_wp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf7dd6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b062e2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2imdf(_df):\n",
    "    _df = _df[['uniq_id']]\n",
    "    _df['license'] = 1\n",
    "    _df['url'] = 'http://farm9.staticflickr.com'\n",
    "    _df['file_name'] = 'test.jpg'\n",
    "    _df['width'] = 640\n",
    "    _df['height'] = 360\n",
    "    _df['date_captured'] = '2013-11-14 11:18:45'\n",
    "    _df.columns = _df.columns.str.replace('uniq_id', 'id')\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59861074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_gt2anno(_df):\n",
    "    image_id = []\n",
    "    caption = []\n",
    "    for index, row in _df.iterrows():\n",
    "        image_id.append(row['image_id'])\n",
    "        caption.append(row['con_gt'])\n",
    "    \n",
    "    df_ = pd.DataFrame()\n",
    "    df_['image_id'] = image_id\n",
    "    df_['id'] = np.arange(len(caption))\n",
    "    df_['caption'] = caption\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "73ba6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gt2anno(_df):\n",
    "    image_id = []\n",
    "    caption = []\n",
    "    for index, row in _df.iterrows():\n",
    "#         print(row['image_id'], row['gt'])\n",
    "        for el in row['gt']:\n",
    "            image_id.append(row['image_id'])\n",
    "            caption.append(el)\n",
    "#         break\n",
    "    df_ = pd.DataFrame()\n",
    "    df_['image_id'] = image_id\n",
    "    df_['id'] = np.arange(len(caption))\n",
    "    df_['caption'] = caption\n",
    "    return df_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2cd34c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def org_2anno(_df):\n",
    "    image_id = []\n",
    "#     caption = []\n",
    "    for index, row in _df.iterrows():\n",
    "        image_id.append(row['image_id'])\n",
    "#         caption.append('pedestrian')\n",
    "    \n",
    "    df_ = pd.DataFrame()\n",
    "    df_['image_id'] = image_id\n",
    "    df_['id'] = np.arange(len(image_id))\n",
    "    df_['caption'] = _df['caption'].to_list()\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07f76e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n",
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n",
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n",
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n",
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n",
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n",
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n",
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n",
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n",
      "/tmp/ipykernel_7796/2853690035.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['license'] = 1\n",
      "/tmp/ipykernel_7796/2853690035.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['url'] = 'http://farm9.staticflickr.com'\n",
      "/tmp/ipykernel_7796/2853690035.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['file_name'] = 'test.jpg'\n",
      "/tmp/ipykernel_7796/2853690035.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['width'] = 640\n",
      "/tmp/ipykernel_7796/2853690035.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['height'] = 360\n",
      "/tmp/ipykernel_7796/2853690035.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  _df['date_captured'] = '2013-11-14 11:18:45'\n"
     ]
    }
   ],
   "source": [
    "gk = df_wp.groupby('topics')\n",
    "pg_dict = dict()\n",
    "for el in gk.groups.keys():\n",
    "    pg_dict[el] = dict()\n",
    "    pg_dict[el]['data'] = gk.get_group(el)\n",
    "    pg_dict[el]['data'] = pg_dict[el]['data'][pg_dict[el]['data']['topic2caption_sim'] >= pg_dict[el]['data']['topic2caption_sim'].quantile(.25)]\n",
    "    pg_dict[el]['data'] = pg_dict[el]['data'].reset_index(drop=True)\n",
    "    temp = pg_dict[el]['data'][['image_id', 'ofa_caption']]\n",
    "    temp.columns = temp.columns.str.replace('ofa_caption', 'caption')\n",
    "    pg_dict[el]['results'] = temp\n",
    "    pg_dict[el]['images'] = id2imdf(pg_dict[el]['data'])\n",
    "    pg_dict[el]['split_annotations'] = gt2anno(pg_dict[el]['data'])\n",
    "    pg_dict[el]['con_annotations'] = concat_gt2anno(pg_dict[el]['data'])\n",
    "    pg_dict[el]['org_annotations'] = org_2anno(pg_dict[el]['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a30aaa14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>id</th>\n",
       "      <th>caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "      <td>One of many control panels in aircraft simulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>507</td>\n",
       "      <td>1</td>\n",
       "      <td>Cartoon scene with military army car vehicle o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>508</td>\n",
       "      <td>2</td>\n",
       "      <td>Cockpit B1900 stock photos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>518</td>\n",
       "      <td>3</td>\n",
       "      <td>Many switches in an aircraft cockpit royalty f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520</td>\n",
       "      <td>4</td>\n",
       "      <td>View of an old aircraft cockpit with two yokes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1792</td>\n",
       "      <td>76</td>\n",
       "      <td>The various air traffic control facilities enc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1795</td>\n",
       "      <td>77</td>\n",
       "      <td>Its Our Passion  Airspace Aviation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1947</td>\n",
       "      <td>78</td>\n",
       "      <td>Lufthansa Business Class on longhaul aircraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1979</td>\n",
       "      <td>79</td>\n",
       "      <td>911 Attacks Pentagon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1992</td>\n",
       "      <td>80</td>\n",
       "      <td>911 flight 93 memorial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id  id                                            caption\n",
       "0        499   0  One of many control panels in aircraft simulat...\n",
       "1        507   1  Cartoon scene with military army car vehicle o...\n",
       "2        508   2                         Cockpit B1900 stock photos\n",
       "3        518   3  Many switches in an aircraft cockpit royalty f...\n",
       "4        520   4  View of an old aircraft cockpit with two yokes...\n",
       "..       ...  ..                                                ...\n",
       "76      1792  76  The various air traffic control facilities enc...\n",
       "77      1795  77                 Its Our Passion  Airspace Aviation\n",
       "78      1947  78      Lufthansa Business Class on longhaul aircraft\n",
       "79      1979  79                               911 Attacks Pentagon\n",
       "80      1992  80                             911 flight 93 memorial\n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg_dict[el]['org_annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15087498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crate_json(t='split_annotations'):\n",
    "    t_data = dict()\n",
    "    t_data['info'] = jdata['info']\n",
    "    t_data['images'] = pg_dict[el]['images'].to_dict('records')\n",
    "    t_data['type'] = jdata['type']\n",
    "    t_data['licenses'] = jdata['licenses']\n",
    "    t_data['annotations'] = pg_dict[el][t].to_dict('records')\n",
    "    return t_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0da233c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_dict = dict()\n",
    "for el in gk.groups.keys():\n",
    "    file_dict[el] = dict()\n",
    "#     print(el)\n",
    "    \n",
    "    s_data = crate_json(t='split_annotations')\n",
    "    c_data = crate_json(t='con_annotations')  \n",
    "    o_data = crate_json(t='org_annotations')  \n",
    "    res = pg_dict[el]['results'].to_dict('records')\n",
    "    \n",
    "    file_dict[el]['results'] = f\"data/{el}_results.json\"\n",
    "    with open(file_dict[el]['results'], \"w\") as final:\n",
    "        json.dump(res, final)\n",
    "    \n",
    "    file_dict[el]['sval'] = f\"data/{el}_sval.json\"\n",
    "    with open(file_dict[el]['sval'], \"w\") as final:\n",
    "        json.dump(s_data, final)\n",
    "    \n",
    "    file_dict[el]['cval'] = f\"data/{el}_cval.json\"\n",
    "    with open(file_dict[el]['cval'], \"w\") as final:\n",
    "        json.dump(c_data, final)\n",
    "    \n",
    "    file_dict[el]['oval'] = f\"data/{el}_oval.json\"\n",
    "    with open(file_dict[el]['oval'], \"w\") as final:\n",
    "        json.dump(o_data, final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3672587e",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6c7d9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(topic='a', anno='s'):\n",
    "    if anno == 's':\n",
    "        annotation_file = file_dict[topic]['sval']\n",
    "    elif anno == 'c':\n",
    "        annotation_file = file_dict[topic]['cval']\n",
    "    else:\n",
    "        annotation_file = file_dict[topic]['oval']\n",
    "        \n",
    "    results_file = file_dict[topic]['results']\n",
    "    coco = COCO(annotation_file)\n",
    "    coco_result = coco.loadRes(results_file)\n",
    "    coco_eval = COCOEvalCap(coco, coco_result)\n",
    "    coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "    coco_eval.evaluate()\n",
    "    return coco_eval.eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fbd50f95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 102 tokens at 2360.94 tokens per second.\n",
      "PTBTokenizer tokenized 97 tokens at 2224.75 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 88, 'reflen': 93, 'guess': [88, 78, 68, 58], 'correct': [7, 0, 0, 0]}\n",
      "ratio: 0.9462365591296104\n",
      "Bleu_1: 0.075\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.028\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.067\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.073\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [0.355 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 3.579 s\n",
      "SPICE: 0.159\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 689 tokens at 14820.23 tokens per second.\n",
      "PTBTokenizer tokenized 408 tokens at 8999.21 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 366, 'reflen': 647, 'guess': [366, 323, 280, 237], 'correct': [142, 56, 32, 19]}\n",
      "ratio: 0.5656877897981983\n",
      "Bleu_1: 0.180\n",
      "Bleu_2: 0.120\n",
      "Bleu_3: 0.092\n",
      "Bleu_4: 0.073\n",
      "computing METEOR score...\n",
      "METEOR: 0.111\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.256\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.440\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [1.12 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.251 s\n",
      "SPICE: 0.171\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 608 tokens at 12508.44 tokens per second.\n",
      "PTBTokenizer tokenized 395 tokens at 7853.80 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 356, 'reflen': 569, 'guess': [356, 316, 276, 239], 'correct': [55, 23, 16, 13]}\n",
      "ratio: 0.6256590509655086\n",
      "Bleu_1: 0.085\n",
      "Bleu_2: 0.058\n",
      "Bleu_3: 0.048\n",
      "Bleu_4: 0.042\n",
      "computing METEOR score...\n",
      "METEOR: 0.046\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.124\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.555\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [0.863 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.604 s\n",
      "SPICE: 0.124\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 647 tokens at 12374.54 tokens per second.\n",
      "PTBTokenizer tokenized 543 tokens at 10558.47 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 486, 'reflen': 590, 'guess': [486, 428, 370, 320], 'correct': [48, 15, 3, 0]}\n",
      "ratio: 0.8237288135579259\n",
      "Bleu_1: 0.080\n",
      "Bleu_2: 0.047\n",
      "Bleu_3: 0.025\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.037\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.096\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.297\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [4.956 seconds]\n",
      "Error: Could not cache item to /home/barzamini/PycharmProjects/pycocoevalcap/spice/cache with key:\n",
      "\"dave wightman poses for his obligatory hero shot in front of a cf104 starfighter on the snowy ramp at 4 wing baden soellingen germany twonbspyears later in the winter of 196970 at the time he was commanding officer of 422 strikeattack squadron the squadrons of the wing were taken from the nuclear bomb delivery role the following year and 422 was disbanded but wightman remained as co of 441 tactical fighter squadron one of only three squadrons that remained in germany wightman racked up 890 hours in the starfighter out of his 6717 total flying hours on about 35 different types of aircraftnbspphoto dave wightman\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.679 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 8.852 s\n",
      "SPICE: 0.062\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 1568 tokens at 33126.70 tokens per second.\n",
      "PTBTokenizer tokenized 572 tokens at 11983.71 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 516, 'reflen': 1512, 'guess': [516, 462, 408, 354], 'correct': [105, 15, 0, 0]}\n",
      "ratio: 0.34126984126961557\n",
      "Bleu_1: 0.030\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.028\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.076\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.055\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [7.609 seconds]\n",
      "Error: Could not cache item to /home/barzamini/PycharmProjects/pycocoevalcap/spice/cache with key:\n",
      "\"airman first class jesse kramer air terminal operations logistics readiness squadron 146th airlift wing channel islands air national guard station califhelps tie down a pallet at joint base elmendorfrichardson anchorage alaska on june 15 2011 the 146th aw sent three squadrons to jber from june 4 to june 18 2011 the air terminal operations squadron logistics readiness squadron and security forces squadron moved down range to complete their respective annual training requirements photo by tech sgt alex koenig\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/barzamini/PycharmProjects/pycocoevalcap/spice/cache with key:\n",
      "\"the american flag secured to the open ramp of the lead 37th airlift squadron c130j super hercules waves in the wind as seven c130j super hercules tail behind as part of an eightship formation in normandy france june 6 2019 the eightship formation flyover was part of the commemoration events in honor of the 75th anniversary of dday in this formation four c130j super hercules belong to the 37th as out of ramstein air base two belonging to the 61st and 62nd as out of little rock air force base and two belonging to the 39th and 40th as out of dyess air force base us air force photo by senior airman kristof j rixmann\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/barzamini/PycharmProjects/pycocoevalcap/spice/cache with key:\n",
      "\"us air force personnel assigned to the 621st contingency response wing 621 crw load equipment into the back of a c130j aircraft assigned to the 115th airlift squadron on an improvised dirt runway at fort hunter liggett california february 8 2022 utilizing the c130j and other department of defense aircraft the 146th contingency response flight and the 621 crw partnered to accomplish skillenhancing training and provide airlift support to the 621 crws evaluated exercise us air national guard photo by staff sgt michelle ulber\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.655 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 11.59 s\n",
      "SPICE: 0.038\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 421 tokens at 8360.79 tokens per second.\n",
      "PTBTokenizer tokenized 314 tokens at 6991.15 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 272, 'reflen': 379, 'guess': [272, 229, 186, 152], 'correct': [41, 8, 4, 2]}\n",
      "ratio: 0.7176781002619587\n",
      "Bleu_1: 0.102\n",
      "Bleu_2: 0.049\n",
      "Bleu_3: 0.033\n",
      "Bleu_4: 0.024\n",
      "computing METEOR score...\n",
      "METEOR: 0.050\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.131\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.350\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [0.756 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 3.842 s\n",
      "SPICE: 0.073\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 234 tokens at 4848.68 tokens per second.\n",
      "PTBTokenizer tokenized 131 tokens at 2796.91 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 116, 'reflen': 219, 'guess': [116, 100, 84, 69], 'correct': [21, 9, 4, 0]}\n",
      "ratio: 0.529680365294385\n",
      "Bleu_1: 0.074\n",
      "Bleu_2: 0.053\n",
      "Bleu_3: 0.038\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.045\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.131\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.222\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [0.443 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 3.766 s\n",
      "SPICE: 0.042\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 3004 tokens at 59007.95 tokens per second.\n",
      "PTBTokenizer tokenized 1350 tokens at 27202.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 1217, 'reflen': 2871, 'guess': [1217, 1083, 949, 819], 'correct': [378, 104, 36, 17]}\n",
      "ratio: 0.4238941135491383\n",
      "Bleu_1: 0.080\n",
      "Bleu_2: 0.044\n",
      "Bleu_3: 0.027\n",
      "Bleu_4: 0.018\n",
      "computing METEOR score...\n",
      "METEOR: 0.064\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.172\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.172\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.6 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [12.130 seconds]\n",
      "Error: Could not cache item to /home/barzamini/PycharmProjects/pycocoevalcap/spice/cache with key:\n",
      "\"whats next by the end of 2020 qantas will have phased out the remaining six boeing 747400er aircraft from its fleet but you can still spot the occasional aircraft a rather prominent 747200 currently sits in the carpark of longreach airport in central queensland at the qantas founders museum some of the fleet will be transferred to other airlines to continue their flying careers while the older models will retire in aviation museums around the world photo graham bennet sammy stewart qantas seat trick no one told you about 15 ways flying is about to change forever inside qantas secret airport compound\"\n",
      "Caption may be too long\n",
      "Error: Could not cache item to /home/barzamini/PycharmProjects/pycocoevalcap/spice/cache with key:\n",
      "\"vhoee boeing 747438er msn 329091308 of qantas named nullarbor at perth airport 26 january 2019 photo ben cambridge returning after operating what may be the last of the special australia day qantas 747 sightseeing flights over antarctica qf2906 is seen taxying in to bay 13 at terminal 4 at 840pm after 125 hours in the air it departed at 805am that morning from bay 13 the flight is operated as a domestic service since it does not actually land in antarctica only overflying this was the first boeing 747438er extended range built by boeing and the first of six er versions ordered new by qantas also the first new 747 delivered with general electric ge cf680c2b5 engines it was rolled out in boeings company livery as n6018n but first flown as n747er on 31 july 2002 following flight tests it was repainted in qantas livery as vhoee and delivered 67 dec 2002 it operated the first sydney dallas fort worth service on 16 may 2011\"\n",
      "Caption may be too long\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [1.705 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 17.10 s\n",
      "SPICE: 0.075\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 728 tokens at 15565.14 tokens per second.\n",
      "PTBTokenizer tokenized 579 tokens at 12538.96 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 526, 'reflen': 675, 'guess': [526, 472, 418, 364], 'correct': [132, 28, 10, 5]}\n",
      "ratio: 0.7792592592581048\n",
      "Bleu_1: 0.189\n",
      "Bleu_2: 0.092\n",
      "Bleu_3: 0.053\n",
      "Bleu_4: 0.035\n",
      "computing METEOR score...\n",
      "METEOR: 0.080\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.178\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.297\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [2.885 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.538 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 7.739 s\n",
      "SPICE: 0.098\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 46 tokens at 542.33 tokens per second.\n",
      "PTBTokenizer tokenized 52 tokens at 1096.52 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 48, 'reflen': 42, 'guess': [48, 43, 38, 33], 'correct': [2, 0, 0, 0]}\n",
      "ratio: 1.1428571428299321\n",
      "Bleu_1: 0.042\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "computing METEOR score...\n",
      "METEOR: 0.007\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.051\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.117\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/barzamini/PycharmProjects/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.3 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Threads( StanfordCoreNLP ) [0.381 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [0.516 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 6.013 s\n",
      "SPICE: 0.000\n"
     ]
    }
   ],
   "source": [
    "split_res_dict = dict()\n",
    "con_res_dict = dict()\n",
    "org_res_dict = dict()\n",
    "for el in gk.groups.keys():\n",
    "#     split_res_dict[el] = calc_metrics(topic=el, anno='s')\n",
    "#     con_res_dict[el] = calc_metrics(topic=el, anno='c')\n",
    "    org_res_dict[el] = calc_metrics(topic=el, anno='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d342954",
   "metadata": {},
   "source": [
    "# Av before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78445ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0787</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.0459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.0221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0784</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0754</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.1022</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0435</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.1391</td>\n",
       "      <td>0.0636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0599</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>0.2077</td>\n",
       "      <td>0.1272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bleu_1   Bleu_2   Bleu_3   Bleu_4   METEOR  ROUGE_L    CIDEr    SPICE\n",
       "count  10.0000  10.0000  10.0000  10.0000  10.0000  10.0000  10.0000  10.0000\n",
       "mean    0.0787   0.0297   0.0090   0.0027   0.0347   0.0809   0.0922   0.0459\n",
       "std     0.0359   0.0170   0.0112   0.0052   0.0130   0.0333   0.0642   0.0352\n",
       "min     0.0219   0.0091   0.0000   0.0000   0.0187   0.0345   0.0305   0.0169\n",
       "25%     0.0546   0.0141   0.0000   0.0000   0.0260   0.0566   0.0404   0.0221\n",
       "50%     0.0784   0.0315   0.0042   0.0000   0.0316   0.0754   0.0614   0.0301\n",
       "75%     0.1022   0.0385   0.0128   0.0020   0.0435   0.1033   0.1391   0.0636\n",
       "max     0.1363   0.0604   0.0282   0.0156   0.0599   0.1312   0.2077   0.1272"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res = []\n",
    "for el in gk.groups.keys():\n",
    "    all_res.append(org_res_dict[el])\n",
    "df_res = pd.DataFrame(all_res)\n",
    "df_res.describe().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43443c66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "Bleu_1: 0.118\n",
      "Bleu_2: 0.038\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.046\n",
      "ROUGE_L: 0.087\n",
      "CIDEr: 0.037\n",
      "SPICE: 0.127\n",
      "\n",
      "b\n",
      "Bleu_1: 0.098\n",
      "Bleu_2: 0.036\n",
      "Bleu_3: 0.013\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.048\n",
      "ROUGE_L: 0.131\n",
      "CIDEr: 0.208\n",
      "SPICE: 0.075\n",
      "\n",
      "c\n",
      "Bleu_1: 0.054\n",
      "Bleu_2: 0.010\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.026\n",
      "ROUGE_L: 0.058\n",
      "CIDEr: 0.064\n",
      "SPICE: 0.033\n",
      "\n",
      "d\n",
      "Bleu_1: 0.057\n",
      "Bleu_2: 0.021\n",
      "Bleu_3: 0.012\n",
      "Bleu_4: 0.008\n",
      "METEOR: 0.023\n",
      "ROUGE_L: 0.034\n",
      "CIDEr: 0.031\n",
      "SPICE: 0.017\n",
      "\n",
      "e\n",
      "Bleu_1: 0.022\n",
      "Bleu_2: 0.009\n",
      "Bleu_3: 0.005\n",
      "Bleu_4: 0.003\n",
      "METEOR: 0.019\n",
      "ROUGE_L: 0.052\n",
      "CIDEr: 0.035\n",
      "SPICE: 0.027\n",
      "\n",
      "f\n",
      "Bleu_1: 0.082\n",
      "Bleu_2: 0.027\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.028\n",
      "ROUGE_L: 0.056\n",
      "CIDEr: 0.059\n",
      "SPICE: 0.019\n",
      "\n",
      "g\n",
      "Bleu_1: 0.075\n",
      "Bleu_2: 0.046\n",
      "Bleu_3: 0.028\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.035\n",
      "ROUGE_L: 0.079\n",
      "CIDEr: 0.170\n",
      "SPICE: 0.027\n",
      "\n",
      "h\n",
      "Bleu_1: 0.041\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.003\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.028\n",
      "ROUGE_L: 0.072\n",
      "CIDEr: 0.049\n",
      "SPICE: 0.043\n",
      "\n",
      "i\n",
      "Bleu_1: 0.104\n",
      "Bleu_2: 0.039\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.035\n",
      "ROUGE_L: 0.109\n",
      "CIDEr: 0.143\n",
      "SPICE: 0.020\n",
      "\n",
      "j\n",
      "Bleu_1: 0.136\n",
      "Bleu_2: 0.060\n",
      "Bleu_3: 0.028\n",
      "Bleu_4: 0.016\n",
      "METEOR: 0.060\n",
      "ROUGE_L: 0.131\n",
      "CIDEr: 0.126\n",
      "SPICE: 0.070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in gk.groups.keys():\n",
    "    print(el)\n",
    "#     print(split_res_dict[el])\n",
    "    for metric, score in org_res_dict[el].items():\n",
    "        print(f'{metric}: {score:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5de7bd7",
   "metadata": {},
   "source": [
    "# Av after wit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc7b89e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>0.0598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>0.0363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0814</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0824</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.0354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0934</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.1002</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>0.0453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.1174</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.0935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.1623</td>\n",
       "      <td>0.3436</td>\n",
       "      <td>0.1158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bleu_1   Bleu_2   Bleu_3   Bleu_4   METEOR  ROUGE_L    CIDEr    SPICE\n",
       "count  10.0000  10.0000  10.0000  10.0000  10.0000  10.0000  10.0000  10.0000\n",
       "mean    0.0953   0.0432   0.0174   0.0077   0.0421   0.1054   0.1372   0.0598\n",
       "std     0.0383   0.0226   0.0177   0.0122   0.0119   0.0366   0.0957   0.0363\n",
       "min     0.0358   0.0138   0.0000   0.0000   0.0299   0.0530   0.0524   0.0222\n",
       "25%     0.0814   0.0240   0.0062   0.0000   0.0338   0.0824   0.0622   0.0354\n",
       "50%     0.0934   0.0445   0.0122   0.0000   0.0396   0.1002   0.1112   0.0453\n",
       "75%     0.1174   0.0561   0.0238   0.0129   0.0443   0.1197   0.1922   0.0935\n",
       "max     0.1603   0.0797   0.0512   0.0302   0.0669   0.1623   0.3436   0.1158"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# org_res_dict\n",
    "all_res = []\n",
    "for el in gk.groups.keys():\n",
    "    all_res.append(org_res_dict[el])\n",
    "df_res = pd.DataFrame(all_res)\n",
    "df_res.describe().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ee78213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "Bleu_1: 0.080\n",
      "Bleu_2: 0.028\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.035\n",
      "ROUGE_L: 0.081\n",
      "CIDEr: 0.062\n",
      "SPICE: 0.109\n",
      "\n",
      "b\n",
      "Bleu_1: 0.118\n",
      "Bleu_2: 0.051\n",
      "Bleu_3: 0.016\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.057\n",
      "ROUGE_L: 0.162\n",
      "CIDEr: 0.195\n",
      "SPICE: 0.107\n",
      "\n",
      "c\n",
      "Bleu_1: 0.092\n",
      "Bleu_2: 0.023\n",
      "Bleu_3: 0.010\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.035\n",
      "ROUGE_L: 0.085\n",
      "CIDEr: 0.063\n",
      "SPICE: 0.047\n",
      "\n",
      "d\n",
      "Bleu_1: 0.085\n",
      "Bleu_2: 0.039\n",
      "Bleu_3: 0.014\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.030\n",
      "ROUGE_L: 0.053\n",
      "CIDEr: 0.054\n",
      "SPICE: 0.022\n",
      "\n",
      "e\n",
      "Bleu_1: 0.041\n",
      "Bleu_2: 0.018\n",
      "Bleu_3: 0.007\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.032\n",
      "ROUGE_L: 0.070\n",
      "CIDEr: 0.065\n",
      "SPICE: 0.035\n",
      "\n",
      "f\n",
      "Bleu_1: 0.117\n",
      "Bleu_2: 0.052\n",
      "Bleu_3: 0.026\n",
      "Bleu_4: 0.016\n",
      "METEOR: 0.044\n",
      "ROUGE_L: 0.119\n",
      "CIDEr: 0.158\n",
      "SPICE: 0.036\n",
      "\n",
      "g\n",
      "Bleu_1: 0.095\n",
      "Bleu_2: 0.071\n",
      "Bleu_3: 0.051\n",
      "Bleu_4: 0.030\n",
      "METEOR: 0.044\n",
      "ROUGE_L: 0.108\n",
      "CIDEr: 0.344\n",
      "SPICE: 0.044\n",
      "\n",
      "h\n",
      "Bleu_1: 0.036\n",
      "Bleu_2: 0.014\n",
      "Bleu_3: 0.006\n",
      "Bleu_4: 0.003\n",
      "METEOR: 0.033\n",
      "ROUGE_L: 0.093\n",
      "CIDEr: 0.052\n",
      "SPICE: 0.053\n",
      "\n",
      "i\n",
      "Bleu_1: 0.130\n",
      "Bleu_2: 0.057\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.044\n",
      "ROUGE_L: 0.120\n",
      "CIDEr: 0.184\n",
      "SPICE: 0.029\n",
      "\n",
      "j\n",
      "Bleu_1: 0.160\n",
      "Bleu_2: 0.080\n",
      "Bleu_3: 0.044\n",
      "Bleu_4: 0.027\n",
      "METEOR: 0.067\n",
      "ROUGE_L: 0.162\n",
      "CIDEr: 0.195\n",
      "SPICE: 0.116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in gk.groups.keys():\n",
    "    print(el)\n",
    "#     print(split_res_dict[el])\n",
    "    for metric, score in org_res_dict[el].items():\n",
    "        print(f'{metric}: {score:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faef0a5",
   "metadata": {},
   "source": [
    "# Av after fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "62480344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bleu_1</th>\n",
       "      <th>Bleu_2</th>\n",
       "      <th>Bleu_3</th>\n",
       "      <th>Bleu_4</th>\n",
       "      <th>METEOR</th>\n",
       "      <th>ROUGE_L</th>\n",
       "      <th>CIDEr</th>\n",
       "      <th>SPICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "      <td>10.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0936</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.2578</td>\n",
       "      <td>0.0842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>0.0543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.0467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.1272</td>\n",
       "      <td>0.2594</td>\n",
       "      <td>0.0742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0607</td>\n",
       "      <td>0.1614</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>0.1172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>0.5555</td>\n",
       "      <td>0.1709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Bleu_1   Bleu_2   Bleu_3   Bleu_4   METEOR  ROUGE_L    CIDEr    SPICE\n",
       "count  10.0000  10.0000  10.0000  10.0000  10.0000  10.0000  10.0000  10.0000\n",
       "mean    0.0936   0.0476   0.0314   0.0192   0.0497   0.1282   0.2578   0.0842\n",
       "std     0.0523   0.0383   0.0288   0.0249   0.0295   0.0616   0.1624   0.0543\n",
       "min     0.0295   0.0000   0.0000   0.0000   0.0071   0.0510   0.0550   0.0000\n",
       "25%     0.0747   0.0199   0.0061   0.0000   0.0303   0.0812   0.1304   0.0467\n",
       "50%     0.0798   0.0482   0.0297   0.0089   0.0459   0.1272   0.2594   0.0742\n",
       "75%     0.0975   0.0569   0.0452   0.0325   0.0607   0.1614   0.3366   0.1172\n",
       "max     0.1890   0.1204   0.0916   0.0731   0.1106   0.2560   0.5555   0.1709"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_res = []\n",
    "for el in gk.groups.keys():\n",
    "    all_res.append(org_res_dict[el])\n",
    "df_res = pd.DataFrame(all_res)\n",
    "df_res.describe().round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1d5e230c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "Bleu_1: 0.075\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.028\n",
      "ROUGE_L: 0.067\n",
      "CIDEr: 0.073\n",
      "SPICE: 0.159\n",
      "\n",
      "b\n",
      "Bleu_1: 0.180\n",
      "Bleu_2: 0.120\n",
      "Bleu_3: 0.092\n",
      "Bleu_4: 0.073\n",
      "METEOR: 0.111\n",
      "ROUGE_L: 0.256\n",
      "CIDEr: 0.440\n",
      "SPICE: 0.171\n",
      "\n",
      "c\n",
      "Bleu_1: 0.085\n",
      "Bleu_2: 0.058\n",
      "Bleu_3: 0.048\n",
      "Bleu_4: 0.042\n",
      "METEOR: 0.046\n",
      "ROUGE_L: 0.124\n",
      "CIDEr: 0.555\n",
      "SPICE: 0.124\n",
      "\n",
      "d\n",
      "Bleu_1: 0.080\n",
      "Bleu_2: 0.047\n",
      "Bleu_3: 0.025\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.037\n",
      "ROUGE_L: 0.096\n",
      "CIDEr: 0.297\n",
      "SPICE: 0.062\n",
      "\n",
      "e\n",
      "Bleu_1: 0.030\n",
      "Bleu_2: 0.012\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.028\n",
      "ROUGE_L: 0.076\n",
      "CIDEr: 0.055\n",
      "SPICE: 0.038\n",
      "\n",
      "f\n",
      "Bleu_1: 0.102\n",
      "Bleu_2: 0.049\n",
      "Bleu_3: 0.033\n",
      "Bleu_4: 0.024\n",
      "METEOR: 0.050\n",
      "ROUGE_L: 0.131\n",
      "CIDEr: 0.350\n",
      "SPICE: 0.073\n",
      "\n",
      "g\n",
      "Bleu_1: 0.074\n",
      "Bleu_2: 0.053\n",
      "Bleu_3: 0.038\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.045\n",
      "ROUGE_L: 0.131\n",
      "CIDEr: 0.222\n",
      "SPICE: 0.042\n",
      "\n",
      "h\n",
      "Bleu_1: 0.080\n",
      "Bleu_2: 0.044\n",
      "Bleu_3: 0.027\n",
      "Bleu_4: 0.018\n",
      "METEOR: 0.064\n",
      "ROUGE_L: 0.172\n",
      "CIDEr: 0.172\n",
      "SPICE: 0.075\n",
      "\n",
      "i\n",
      "Bleu_1: 0.189\n",
      "Bleu_2: 0.092\n",
      "Bleu_3: 0.053\n",
      "Bleu_4: 0.035\n",
      "METEOR: 0.080\n",
      "ROUGE_L: 0.178\n",
      "CIDEr: 0.297\n",
      "SPICE: 0.098\n",
      "\n",
      "j\n",
      "Bleu_1: 0.042\n",
      "Bleu_2: 0.000\n",
      "Bleu_3: 0.000\n",
      "Bleu_4: 0.000\n",
      "METEOR: 0.007\n",
      "ROUGE_L: 0.051\n",
      "CIDEr: 0.117\n",
      "SPICE: 0.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for el in gk.groups.keys():\n",
    "    print(el)\n",
    "#     print(split_res_dict[el])\n",
    "    for metric, score in org_res_dict[el].items():\n",
    "        print(f'{metric}: {score:.3f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d7bf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
